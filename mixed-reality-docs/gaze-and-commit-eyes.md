---
title: 目の視線入力とコミット
description: 目の視線入力とコミットの入力モデルの概要
author: sostel
ms.author: sostel
ms.date: 05/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: 視線追跡, Mixed Reality, 入力, 目の視線入力, 目のターゲット設定, HoloLens 2, 視線に基づく選択
ms.openlocfilehash: 89f5031635f2b67ba4c9afdf605559c2b9da4ac2
ms.sourcegitcommit: 9df82dba06a91a8d2cedbe38a4328f8b86bb2146
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 04/29/2020
ms.locfileid: "73437828"
---
# <a name="eye-gaze-and-commit"></a>目の視線入力とコミット
_目の視線入力とコミット_は、[視線入力とコミット](gaze-and-commit.md)入力モデルの特殊なケースです。これには、見つめるだけでオブジェクトをターゲットにし、手のジェスチャ、音声コマンド、周辺入力機器 (ゲーム コントローラーなど) などのセカンダリ _コミット_入力を使用してそのオブジェクトを操作することが含まれます。 

HoloLens 2 では、頭の視線入力ではなく目の視線入力を使用することで_視線入力とコミット_をより迅速で快適なものにできます。 これにより、一般的な[頭の視線入力とコミット](gaze-and-commit.md)の相互作用モデルを拡張できます。 
1. ターゲットを見つめるだけ 
2. ターゲットを選択するという意図を示すために、次のような第 2 の明示的な入力を実行します。  
   - 手のジェスチャ (エアタップなど)
   - ボタン押下 (Bluetooth キーボードやクリッカーなど)
   - 音声コマンド (「選択」など)
   - ドウェル (つまり、ユーザーはターゲットを見つめ続けることで選択する)

ただし、目の視線入力はいくつかの点で頭の視線入力とまったく異なる動作をするため、さまざまな固有の課題があります。 [目の視線入力設計ガイドライン](eye-tracking.md)に、ホログラフィック アプリで視線追跡を入力として使用する場合に考慮すべき一般的なメリットと課題の概要が記載されています。 このセクションでは、_目の視線入力とコミット_に関する特定の設計考慮事項を中心に説明します。
まず、私たちの目は非常に速く動くため、視界からすばやくターゲット設定を行うのに適しています。 したがって、目の視線入力は、特に、エアタップやボタン押下などの高速コミットと組み合わせたときに、迅速な視線入力とコミットのアクションに理想的と言えます。
   
ここでは、この種の相互作用に目の視線入力を使用する場合の設計ガイドラインを示し、頭の視線入力と目の視線入力の違いについて考慮しておく必要がある点を説明します。

## <a name="design-guidelines-for-eye-gaze-and-commit"></a>目の視線入力とコミットに関する設計ガイドライン

**カーソルを表示しない**:頭の視線入力の使用中はカーソルを使わずに操作するのはほぼ不可能なのに対して、目の視線入力の使用中はカーソルがたちまち集中の邪魔をしたり、目障りになったりします。 視線追跡が機能しているかどうかということと、現在見ているターゲットが正しく検出されたかどうかをユーザーに知らせるためにカーソルに頼るのではなく、繊細なビジュアル ハイライトを使用します (詳細については後述します)。

**繊細なブレンド ホバー フィードバックを追求する**:頭の視線入力にとっては優れた視覚的フィードバックが、目の視線入力にとっては不快で混乱するエクスペリエンスになる可能性があります。 目の動きは非常に速いため、視野の中の点から点へとすばやく動くことにご注意ください。 周りを見回しているときに急にハイライトが変化 (オン/オフ) すると、フィードバックがちらつく可能性があります。 そのため、ホバー フィードバックを提供する場合は、スムーズ ブレンドイン ハイライト (視線を外す場合はスムーズ ブレンドアウト ハイライト) を使用することをお勧めします。 これは、ターゲットを見たときに、最初はフィードバックにほとんど気付かないことを意味します。 500 - 1000 ミリ秒かけて、ハイライトの輝度が上がります。 初級ユーザーは見つめているターゲットが正しく判別されたことを確かめようとしてターゲットを見つめ続けるかもしれませんが、上級ユーザーはフィードバックが最大輝度になるのを待たずにすばやく視線入力とコミットを実行できます。 加えて、ホバー フィードバックをフェードアウトするときにブレンドアウトを使用することもお勧めします。 調査により、周辺視野 (自分が注視していない視野領域) では動きやコントラストの急激な変化に気付きやすいことがわかりました。
フェードアウトをブレンドインと同じほど遅くする必要はありません。 このことは、ハイライトのコントラストが高い場合や色が変化する場合にのみ重要です。 ホバー フィードバックが極めて繊細な場合は、初めは違いに気付かないかもしれません。

**視線入力とコミット信号を同期させるよう配慮する**:入力信号の同期は、単純なエア タップやボタン押下の場合は大きな問題ではありません。 長い音声コマンドや複雑な手のジェスチャが必要になる可能性のある、より複雑なコミット アクションを使用する場合は注意が必要です。 ターゲットを見つめて、長い音声コマンドを発音する場合を想像してください。 発音するのに必要な時間と、発音された内容をシステムが検出するのに必要な時間を考えると、目の視線入力はシーン内の離れた場所にある新しいターゲットに移動している可能性があります。 そのため、コマンドが認識されるまでターゲットを見つめ続けなければならないことをユーザーに気付かせるか、コマンドの開始とユーザーがその時点で見ていたものを特定するという方法で入力を処理する必要があります。

## <a name="see-also"></a>関連項目
* [視線ベースの操作] (eye-gaze-interaction.md)
* [HoloLens 2 上の視線追跡] (eye-tracking.md)
* [視線入力とコミット](gaze-and-commit.md)
* [視線入力とドウェル](gaze-and-dwell.md)
* [手 - 直接操作](direct-manipulation.md)
* [手 - ジェスチャ](gaze-and-commit.md#composite-gestures)
* [手 - ポイントとコミット](point-and-commit.md)
* [本能的な操作](interaction-fundamentals.md)
* [音声入力](voice-input.md)
