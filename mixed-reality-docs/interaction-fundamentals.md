---
title: 本能的な操作
description: Mixed Reality プラットフォーム全体に織り込まれている、シンプルで本能的な操作の理念について説明します。
author: shengkait
ms.author: shentan
ms.date: 04/11/2019
ms.topic: article
ms.localizationpriority: high
keywords: Mixed Reality, 視線入力, 視線入力ターゲット設定, 対話, 設計, HoloLens, MMR, マルチモーダル
ms.openlocfilehash: 6b54d6e844c1b501a0835fc3a48deb4932ba551d
ms.sourcegitcommit: 9df82dba06a91a8d2cedbe38a4328f8b86bb2146
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 04/29/2020
ms.locfileid: "74539736"
---
# <a name="introducing-instinctual-interactions"></a>本能的な操作の概要

![手で遠隔操作する](images/04_InteractionFundamentals.png)

シンプルで本能的な操作の理念は、Mixed Reality (MR) プラットフォーム全体に織り込まれています。 アプリケーションのデザイナーや開発者が顧客に簡単で直感的な操作を提供できるように、3 つの手順を使用しています。 

1 つ目として、センサーと入力のテクノロジ (自然言語入力に加え、手の追跡と視線追跡が含まれます) をまとめることで、シームレスなマルチモーダル操作モデルを実現できるようにしました。  
調査によれば、本能的なエクスペリエンスを作成する鍵となるのは、個々の入力をベースとせずに、マルチモーダル フレームワーク内で設計や開発を行うことです。

2 つ目として、多くの開発者が複数の HoloLens デバイス (HoloLens 2 と HoloLens (第 1 世代) 、HoloLens と VR など) をターゲットにしていることを認識しています。  
このため、各デバイスで入力テクノロジが異なる場合でも、複数のデバイスで動作するように操作モデルを設計しています。  
たとえば、6DoF コントローラーによる Windows イマーシブ ヘッドセットの遠隔操作や、HoloLens 2 での遠隔操作は、どちらも同じアフォーダンスとパターンを使用しているため、クロスデバイス アプリケーションを簡単に開発して、自然なユーザー操作を実現できます。 

MR では効果的で魅力的な魔法のような何千もの操作が実現できますが、ユーザーが成功と優れたエクスペリエンスを実感できる最善の方法は、アプリケーションで意図的にエンドツーエンドの単一操作モデルを使用することであることがわかっています。 そのため、この操作ガイドに次の 3 つのことを含めました。
* 3 つの主要な操作モデルと、それぞれに必要なコンポーネントとパターンに関する具体的なガイダンス。
* このプラットフォームが提供するその他のメリットに関する補足的なガイダンス。
* 開発シナリオに適した操作モデルの選択に役立つ全般的なガイダンス。

## <a name="multimodal-interaction-models"></a>マルチモーダル操作モデル

調査とお客様からのフィードバックに基づき、3 つの主要な操作モデルが大半の Mixed Reality エクスペリエンスに適していることがわかりました。 多くの点で、操作モデルはワークフローの完了方法に関するユーザーのメンタル モデルです。 各操作モデルは一連の顧客ニーズに合わせて最適化されており、適切に使用すれば、どれもが強力かつ便利に使用できます。 

次の表は、簡単な概要です。 各操作モデルを使用するための詳細情報は、イメージとコード サンプルを含むページにリンクしています。 

<br>
<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><strong>Model</strong></td>
        <td><strong>シナリオ例</strong></td>
        <td><strong>適した使用方法</strong></td>
        <td><strong>ハードウェア</strong></td>
    </tr>
    <tr>
        <td><a href="hands-and-tools.md">手とモーション コントローラー</a></td>
        <td>空間レイアウトやデザインなどの 3D 空間エクスペリエンス、コンテンツの操作、またはシミュレーション。</td>
        <td>音声、視線追跡、頭の視線入力と組み合わせると、新しいユーザーに最適。 習得が容易。 手の追跡と 6 DoF コントローラーで一貫性のある UX。</td>
        <td>HoloLens 2<br>イマーシブ ヘッドセット</td>
    </tr>
    <tr>
        <td><a href="hands-free.md">ハンズフリー</a></td>
        <td>実地学習、メンテナンスなど、ユーザーの手がふさがっている場合のコンテキスト対応のエクスペリエンス。</td>
        <td>いくらかの学習が必要。 手が使用できない場合、デバイスにより音声と自然言語が組み合わされる。</td>
        <td>HoloLens 2<br>HoloLens (第 1 世代)<br>イマーシブ ヘッドセット</td>
    </tr>
    <tr>
        <td><a href="gaze-and-commit.md">視線入力とコミット</a></td>
        <td>3D プレゼンテーション、デモなどのクリック スルー エクスペリエンス。</td>
        <td>移動を除く HMD のトレーニングが必要。 アクセシビリティ コントローラーに最適。 HoloLens (第 1 世代) に最適。</td>
        <td>HoloLens 2<br>HoloLens (第 1 世代)<br>イマーシブ ヘッドセット<br>モバイル AR</td>
    </tr>
</table>
<br>

ユーザー操作エクスペリエンスのギャップをなくす最善の方法は、1 つのモデルのガイダンスに最初から最後まで従うことです。

次のセクションでは、これらの操作モデルからいずれかを選択して実装する手順について説明します。  
 
### <a name="by-the-end-of-this-page-you-will-understand-our-guidance-on"></a>このページでは、以下についてのガイダンスを理解することができます。
 
* 顧客の操作モデルの選択
* 操作モデルの実装
* 操作モデル間の遷移
* 次の手順の設計


## <a name="choose-an-interaction-model-for-your-customer"></a>顧客の操作モデルを選択する

通常、開発者と作成者は、顧客が使用できる操作の種類を考慮しています。 顧客中心の設計アプローチを促進するために、次のガイダンスに従って、顧客向けに最適化された操作モデルを選択することをお勧めします。

### <a name="why-follow-this-guidance"></a>ガイダンスに従う理由

* 操作モデルは、物理効果、認識効果、直感性、学習性など、主観的および客観的な基準でテストされます。 
* 操作が異なるため、操作モデル間でビジュアルやオーディオのアフォーダンスやオブジェクトの動作が異なる可能性があります。  
* ハンド レイと頭の視線カーソルを同時に使用するなど、複数の操作モデルの一部を組み合わせると、アフォーダンスが競合するリスクが発生します。 その結果、ユーザーが困惑したり混乱したりする可能性があります。

アフォーダンスと動作を最適化する例を操作モデルごとに示します。 新しいユーザーから、 _「システムが動作していることはどうすればわかりますか」_ 、 _「何ができるかはどうすればわかりますか」_ 、 _「自分がしたことをシステムが理解していることはどうすればわかりますか」_ などの、よく似た質問をしばしば受けます。

<br>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><strong>Model</strong></td>
        <td><strong>動作していることはどうすればわかりますか?</strong></td>
        <td><strong>何ができるかはどうすればわかりますか?</strong></td>
        <td><strong>自分が何をしたかはどうすればわかりますか?</strong></td>
    </tr>
    <tr>
        <td><a href="hands-and-tools.md">手とモーション コントローラー</a></td>
        <td>ハンド メッシュが見える、指先アフォーダンスまたは手やコントローラーの光線が見える。</td>
        <td>オブジェクトに手を近づけると、グラブ可能なハンドルや境界ボックスが表示される。</td>
        <td>音が聞こえ、グラブやリリースのアニメーションが見える。</td>
    </tr>
    <tr>
        <td><a href="gaze-and-commit.md">頭の視線入力とコミット</a></td>
        <td>視野の中央にカーソルが見える。</td>
        <td>カーソルを特定のオブジェクトに重ねると、カーソルの状態が変わる。</td>
        <td>行動すると、視覚または音声でわかる。</td>
    </tr>   
    <tr>
        <td><a href="hands-free.md">ハンズフリー (頭の視線入力とドウェル)</a></td>
        <td>視野の中央にカーソルが見える。</td>
        <td>インタラクティブなオブジェクトにドウェルすると、進行状況のインジケーターが見える。</td>
        <td>行動すると、視覚または音声でわかる。</td>
    </tr>
    <tr>
        <td><a href="hands-free.md">ハンズフリー (音声コマンド)</a></td>
        <td>リスニング インジケーターとシステムが聞いた音を表示するキャプションが見える。</td>
        <td>音声プロンプトとヒントが聞こえる。 次のように言います。音声操作の項目 フィードバックが得られる。</td>
        <td>コマンドを与えると、視覚または音声でわかる。必要な場合は不明瞭解消用の UX が提供される。</a></td>
    </tr>
</table>

### <a name="below-are-questions-that-weve-found-help-teams-select-an-interaction-model"></a>ヘルプ チームが操作モデルを選択する際に使用している質問を次に示します。
 
1.  Q:ユーザーがホログラムにタッチして細かい操作を行うことはありますか?<br><br>
A:その場合は、厳密なターゲット指定や操作を行うために、手とモーション コントローラーの操作モデルを確認します。
 
2.  Q:ユーザーは、現実世界で作業を行うために、手を空けておく必要がありますか?<br><br>
A:その場合は、ハンズフリー操作モデルを確認します。このモデルは、視線入力または音声ベースの操作で優れたハンズフリー エクスペリエンスを提供します。
 
3.  Q:ユーザーには MR アプリケーションの操作を学習する時間はありますか? それとも、最低限の学習で操作を行う必要がありますか?<br><br>
A:最低限の学習で最も直感的に操作を行いたい場合、ユーザーが手を使って操作できるのであれば、手とモーション コントローラーのモデルをお勧めします。
 
4.  Q:ユーザーがポイントしたり操作したりする際、モーション コントローラーを使用しますか?<br><br>
A:手とモーション コントローラーのモデルには、モーション コントローラーを使用してすばらしいエクスペリエンスを実現するためのガイダンスがすべて含まれています。
 
5.  Q:ユーザーは、アクセシビリティ コントローラーやクリッカーなどの一般的な Bluetooth コントローラーを使用しますか?<br><br>
A:すべての非追跡コントローラーには、頭の視線入力とコミットのモデルをお勧めします。 ユーザーが単純な「ターゲット指定とコミット」機構によるエクスペリエンス全体を利用できるように設計されています。 
 
6.  Q:ユーザーは、UI コントロールが詰まったレイアウトを操作するのではなく、「クリックスルー」によってのみエクスペリエンスを進行させることができますか (たとえば、3D スライド ショーのような環境)?<br><br>
A:ユーザーが多くの UI を制御する必要がない場合は、頭の視線入力とコミットを使うと、ターゲットの指定について悩むことなく学習できるオプションを提供できます。 
 
7.  Q:ユーザーは HoloLens (第 1 世代) と HoloLens 2/Windows Mixed Reality イマーシブ ヘッドセット (VR) の両方を使用しますか?<br><br>
A:頭の視線入力とコミットは HoloLens (第 1 世代) の操作モデルであるため、HoloLens (第 1 世代) をサポートする作成者は、ユーザーが HoloLens (第 1 世代) ヘッドセットを使用する可能性があるすべての機能やモードで、頭の視線入力とコミットを使用することをお勧めします。 複数の世代の HoloLens で優れたエクスペリエンスを作成する詳しい方法については、*操作モデルの遷移*について取り上げた次のセクションを参照してください。
 
8.  Q:通常は移動可能 (広い領域をカバーする、またはスペース間を移動する) なユーザーと、1 つのスペースで作業することが多いユーザーを比較するとどうなりますか?<br><br>
A:どの操作モデルでも、これらのユーザーに対応できます。  

> [!NOTE]
> アプリの設計に特化したガイダンスは、[近日中に公開](news.md)します。


## <a name="transitioning-interaction-models"></a>操作モデルの遷移
複数の操作モデルが必要になるユース ケースもあります。 たとえば、アプリケーションの作成フローで _"手とモーション コントローラー操作モデル"_ を利用しつつ、現場技術者向けにはハンズフリー モードを使用する場合などです。
エクスペリエンスに複数の操作モデルが必要な場合、あるモデルから別のモデルに遷移する際に、多くのユーザー (特に、Mixed Reality を初めて使用するユーザー) が困難を感じることに留意する必要があります。

> [!Note]
> 開発者やデザイナーが使用できるガイダンスの作成に常に取り組んでおり、複数の MR 操作モデルを使用するための方法、タイミング、および理由についてお知らせしています。
 

## <a name="see-also"></a>関連項目
* [快適性](comfort.md)
* [視線ベースの操作](eye-gaze-interaction.md)
* [HoloLens 2 上の視線追跡](eye-tracking.md)
* [視線入力とコミット](gaze-and-commit.md)
* [視線入力とドウェル](gaze-and-dwell.md)
* [手 - 直接操作](direct-manipulation.md)
* [手 - ジェスチャ](gaze-and-commit.md#composite-gestures)
* [手 - ポイントとコミット](point-and-commit.md)
* [本能的な操作](interaction-fundamentals.md)
* [モーション コントローラー](motion-controllers.md)
* [空間マッピング](spatial-mapping.md)
* [立体音響の設計](spatial-sound-design.md)
* [音声入力](voice-input.md)


